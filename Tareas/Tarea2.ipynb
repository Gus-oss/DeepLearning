{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24a0f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------Liberias---------------------------------\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PySpark\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:\\\\hadoop\"\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import hour, dayofweek, col, rand, monotonically_increasing_id\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Configurar TensorFlow para modo CPU solamente\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "#---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5022b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------\n",
    "# Crear SparkSession con configuración de memoria optimizada\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RedNeuronal_Taxi\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.fallback.enabled\", \"true\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "#---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d760320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros limpios: 2,716,383\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       2| 2024-01-01 00:57:55|  2024-01-01 01:17:43|              1|         1.72|         1|                 N|         186|          79|           2|       17.7|  1.0|    0.5|       0.0|         0.0|                  1.0|        22.7|                 2.5|        0.0|\n",
      "|       1| 2024-01-01 00:03:00|  2024-01-01 00:09:36|              1|          1.8|         1|                 N|         140|         236|           1|       10.0|  3.5|    0.5|      3.75|         0.0|                  1.0|       18.75|                 2.5|        0.0|\n",
      "|       1| 2024-01-01 00:17:06|  2024-01-01 00:35:01|              1|          4.7|         1|                 N|         236|          79|           1|       23.3|  3.5|    0.5|       3.0|         0.0|                  1.0|        31.3|                 2.5|        0.0|\n",
      "|       1| 2024-01-01 00:36:38|  2024-01-01 00:44:56|              1|          1.4|         1|                 N|          79|         211|           1|       10.0|  3.5|    0.5|       2.0|         0.0|                  1.0|        17.0|                 2.5|        0.0|\n",
      "|       1| 2024-01-01 00:46:51|  2024-01-01 00:52:57|              1|          0.8|         1|                 N|         211|         148|           1|        7.9|  3.5|    0.5|       3.2|         0.0|                  1.0|        16.1|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------\n",
    "# Cargar y preparar datos\n",
    "DATA_PATH = \"C:/Users/PC/Documents/DocumentosGustavo/Github/Maestria/BigData/nyc-taxi-spark/data/yellow/2024/yellow_tripdata_2024-01.parquet\"\n",
    "df = spark.read.parquet(DATA_PATH)\n",
    "\n",
    "# Limpiar y preparar datos\n",
    "df_clean = df.select(\n",
    "    col(\"trip_distance\").cast(\"double\"),\n",
    "    col(\"passenger_count\").cast(\"double\"),\n",
    "    col(\"fare_amount\").cast(\"double\"),\n",
    "    hour(\"tpep_pickup_datetime\").alias(\"hour\"),\n",
    "    dayofweek(\"tpep_pickup_datetime\").alias(\"day\")\n",
    ").filter(\n",
    "    (col(\"trip_distance\") > 0) & (col(\"trip_distance\") < 50) &\n",
    "    (col(\"passenger_count\") > 0) & (col(\"passenger_count\") <= 6) &\n",
    "    (col(\"fare_amount\") > 2) & (col(\"fare_amount\") < 100)\n",
    ")\n",
    "\n",
    "total_registros = df_clean.count()\n",
    "print(f\"Registros limpios: {total_registros:,}\")\n",
    "df.show(5)\n",
    "#---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd13c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usando fracción de muestra: 0.0368 (100,000 registros)\n",
      "Convirtiendo a pandas en lotes...\n",
      "Shape pandas: (99980, 5)\n"
     ]
    }
   ],
   "source": [
    "# Calcular tamaño de muestra\n",
    "SAMPLE_SIZE = 100000  # 100k registros\n",
    "sample_fraction = min(SAMPLE_SIZE / total_registros, 0.05)  # Máximo 5% ó 100k\n",
    "\n",
    "print(f\"\\nUsando fracción de muestra: {sample_fraction:.4f} ({int(sample_fraction * total_registros):,} registros)\")\n",
    "\n",
    "df_sample = df_clean.sample(withReplacement=False, fraction=sample_fraction, seed=42)\n",
    "\n",
    "# Convertir a pandas con manejo de memoria\n",
    "print(\"Convirtiendo a pandas en lotes...\")\n",
    "\n",
    "# Método 1: Directo pero con límite\n",
    "try:\n",
    "    pdf = df_sample.limit(SAMPLE_SIZE).toPandas()\n",
    "    print(f\"Shape pandas: {pdf.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error en conversión directa: {e}\")\n",
    "    print(\"Usando método alternativo...\")\n",
    "    \n",
    "    # Método 2: Recolectar en lotes, por si la primera no funciona \n",
    "    pdf = pd.DataFrame()\n",
    "    batch_size = 50000\n",
    "    \n",
    "    # Obtener total de filas en la muestra\n",
    "    sample_count = df_sample.count()\n",
    "    num_batches = (sample_count + batch_size - 1) // batch_size\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        print(f\"Procesando lote {i+1}/{num_batches}\")\n",
    "        batch_df = df_sample.limit(batch_size).toPandas()\n",
    "        pdf = pd.concat([pdf, batch_df], ignore_index=True)\n",
    "        # Liberar memoria\n",
    "        del batch_df\n",
    "        \n",
    "        # Forzar garbage collection\n",
    "        import gc\n",
    "        gc.collect()\n",
    "    \n",
    "    print(f\"Shape pandas final: {pdf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d1686b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (99980, 4)\n",
      "Target shape: (99980,)\n",
      "\n",
      "Train: 79,984 registros\n",
      "Test: 19,996 registros\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------\n",
    "# Preparar features y target\n",
    "def prepare_data_pandas(pdf):\n",
    "    \"\"\"Preparar datos para TensorFlow\"\"\"\n",
    "    # Normalizar features\n",
    "    pdf['trip_distance_norm'] = pdf['trip_distance'] / 50.0\n",
    "    pdf['passenger_norm'] = pdf['passenger_count'] / 6.0\n",
    "    pdf['hour_norm'] = pdf['hour'] / 24.0\n",
    "    pdf['day_norm'] = (pdf['day'] - 1) / 6.0\n",
    "    \n",
    "    # Normalizar target\n",
    "    pdf['fare_norm'] = (pdf['fare_amount'] - 2.0) / (100.0 - 2.0)\n",
    "    pdf['fare_norm'] = pdf['fare_norm'].clip(0, 1)\n",
    "    \n",
    "    # Features y target\n",
    "    features = pdf[['trip_distance_norm', 'passenger_norm', 'hour_norm', 'day_norm']].values\n",
    "    target = pdf['fare_norm'].values\n",
    "    \n",
    "    return features, target\n",
    "\n",
    "X, y = prepare_data_pandas(pdf)\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Dividir en train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTrain: {X_train.shape[0]:,} registros\")\n",
    "print(f\"Test: {X_test.shape[0]:,} registros\")\n",
    "\n",
    "#---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4cd7fa",
   "metadata": {},
   "source": [
    "Arquitectura de la red neuronal: \n",
    "- Capa oculta: 4 neuronas con activación sigmoide\n",
    "- Capa de salida: 1 neurona con activación sigmoide\n",
    "- Función de perdida: MAE\n",
    "- Optimizador: ADAM \n",
    "- Epoc: 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29b71447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m40\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81</span> (324.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81\u001b[0m (324.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81</span> (324.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m81\u001b[0m (324.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Entrenando el modelo\n",
      "==================================================\n",
      "Epoch 1/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0353 - mae: 0.1467 - val_loss: 0.0059 - val_mae: 0.0600\n",
      "Epoch 2/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0427 - val_loss: 0.0028 - val_mae: 0.0364\n",
      "Epoch 3/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0031 - mae: 0.0365 - val_loss: 0.0027 - val_mae: 0.0351\n",
      "Epoch 4/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0353 - val_loss: 0.0026 - val_mae: 0.0343\n",
      "Epoch 5/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0339 - val_loss: 0.0024 - val_mae: 0.0327\n",
      "Epoch 6/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0318 - val_loss: 0.0022 - val_mae: 0.0298\n",
      "Epoch 7/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0291 - val_loss: 0.0020 - val_mae: 0.0274\n",
      "Epoch 8/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0023 - mae: 0.0270 - val_loss: 0.0019 - val_mae: 0.0264\n",
      "Epoch 9/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0022 - mae: 0.0259 - val_loss: 0.0019 - val_mae: 0.0251\n",
      "Epoch 10/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0022 - mae: 0.0253 - val_loss: 0.0019 - val_mae: 0.0241\n",
      "\n",
      "==================================================\n",
      "Evaluación\n",
      "==================================================\n",
      "Test Loss (MSE): 0.0022\n",
      "Test MAE: 0.0243\n",
      "\n",
      "Predicciones vs Reales (valores normalizados):\n",
      "--------------------------------------------------\n",
      "Pred: 0.064 | Real: 0.053 | Diff: 0.011\n",
      "Pred: 0.084 | Real: 0.074 | Diff: 0.010\n",
      "Pred: 0.069 | Real: 0.060 | Diff: 0.008\n",
      "Pred: 0.077 | Real: 0.103 | Diff: 0.026\n",
      "Pred: 0.079 | Real: 0.060 | Diff: 0.019\n",
      "Pred: 0.725 | Real: 0.861 | Diff: 0.137\n",
      "Pred: 0.082 | Real: 0.067 | Diff: 0.014\n",
      "Pred: 0.093 | Real: 0.096 | Diff: 0.003\n",
      "Pred: 0.064 | Real: 0.046 | Diff: 0.018\n",
      "Pred: 0.071 | Real: 0.060 | Diff: 0.011\n"
     ]
    }
   ],
   "source": [
    "# Crear y entrenar modelo\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(8, activation='relu', input_shape=(4,)),\n",
    "        Dense(4, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "# Entrenar localmente\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Entrenando el modelo\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Evaluación\")\n",
    "print(\"=\"*50)\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss (MSE): {loss:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "\n",
    "# Mostrar algunas predicciones\n",
    "print(\"\\nPredicciones vs Reales (valores normalizados):\")\n",
    "print(\"-\" * 50)\n",
    "predictions = model.predict(X_test[:10], verbose=0)\n",
    "for i in range(10):\n",
    "    print(f\"Pred: {predictions[i][0]:.3f} | Real: {y_test[i]:.3f} | Diff: {abs(predictions[i][0] - y_test[i]):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
