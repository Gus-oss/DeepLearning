{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ğŸš€ SOLUCIÃ“N FINAL: 100% RDD Sin Timeout\n",
    "## Optimizado, Robusto y Probado en Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "libraries",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ LibrerÃ­as importadas\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:\\\\hadoop\"\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"âœ“ LibrerÃ­as importadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spark_config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Spark con timeouts aumentados\n",
      "  Network timeout: 800s\n",
      "  Worker timeout: 600s\n"
     ]
    }
   ],
   "source": [
    "#----------------SparkSession CON TIMEOUTS AUMENTADOS-------------------------\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DeepLearning_100RDD_FINAL\") \\\n",
    "    .master(\"local[8]\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.memory\", \"12g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"8g\") \\\n",
    "    .config(\"spark.network.timeout\", \"800s\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"60s\") \\\n",
    "    .config(\"spark.python.worker.timeout\", \"600s\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"16\") \\\n",
    "    .config(\"spark.default.parallelism\", \"16\") \\\n",
    "    .config(\"spark.rdd.compress\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(\"âœ“ Spark con timeouts aumentados\")\n",
    "print(\"  Network timeout: 800s\")\n",
    "print(\"  Worker timeout: 600s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cargando dataset...\n",
      "âœ“ Dataset: 2,964,624 registros\n"
     ]
    }
   ],
   "source": [
    "#----------------------Cargar datos-----------------------------------------------\n",
    "DATA_PATH = \"C:/Users/PC/Documents/DocumentosGustavo/Github/Maestria/BigData/nyc-taxi-spark/data/yellow/2024/yellow_tripdata_2024-01.parquet\"\n",
    "\n",
    "print(\"\\nCargando dataset...\")\n",
    "df = spark.read.parquet(DATA_PATH)\n",
    "print(f\"âœ“ Dataset: {df.count():,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feature_eng",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando features...\n",
      "âœ“ Completado en 87.4s: 2,722,784 registros\n"
     ]
    }
   ],
   "source": [
    "#----------------------Feature Engineering----------------------------------------\n",
    "def extract_and_scale_features(row):\n",
    "    trip_distance, passenger_count, datetime, fare_amount = row\n",
    "    \n",
    "    if (trip_distance is None or trip_distance <= 0 or trip_distance >= 100 or\n",
    "        passenger_count is None or passenger_count <= 0 or passenger_count > 6 or\n",
    "        datetime is None or\n",
    "        fare_amount is None or fare_amount <= 0 or fare_amount >= 200):\n",
    "        return None\n",
    "    \n",
    "    hour_value = float(datetime.hour)\n",
    "    day_of_week = float(datetime.weekday() + 1)\n",
    "    \n",
    "    features = [\n",
    "        float((trip_distance - 3.0) / 5.0),\n",
    "        float((passenger_count - 1.5) / 1.0),\n",
    "        float((hour_value - 12.0) / 7.0),\n",
    "        float((day_of_week - 4.0) / 2.0)\n",
    "    ]\n",
    "    \n",
    "    return (features, float(fare_amount))\n",
    "\n",
    "print(\"\\nProcesando features...\")\n",
    "start = time.time()\n",
    "\n",
    "rdd_features = df.select(\n",
    "    \"trip_distance\", \"passenger_count\", \"tpep_pickup_datetime\", \"fare_amount\"\n",
    ").rdd.map(lambda row: (\n",
    "    row.trip_distance, row.passenger_count, row.tpep_pickup_datetime, row.fare_amount\n",
    "))\n",
    "\n",
    "rdd_scaled = rdd_features \\\n",
    "    .map(extract_and_scale_features) \\\n",
    "    .filter(lambda x: x is not None) \\\n",
    "    .repartition(16) \\\n",
    "    .cache()\n",
    "\n",
    "total_scaled = rdd_scaled.count()\n",
    "print(f\"âœ“ Completado en {time.time()-start:.1f}s: {total_scaled:,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Train: 2,177,985\n",
      "âœ“ Test: 544,799\n"
     ]
    }
   ],
   "source": [
    "#----------------------DivisiÃ³n Train/Test----------------------------------------\n",
    "train_rdd, test_rdd = rdd_scaled.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "from pyspark import StorageLevel\n",
    "train_rdd = train_rdd.repartition(16).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "test_rdd = test_rdd.repartition(8).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "train_count = train_rdd.count()\n",
    "test_count = test_rdd.count()\n",
    "\n",
    "print(f\"\\nâœ“ Train: {train_count:,}\")\n",
    "print(f\"âœ“ Test: {test_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Modelo creado\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m320\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             â”‚           \u001b[38;5;34m528\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              â”‚           \u001b[38;5;34m136\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚             \u001b[38;5;34m9\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,457</span> (13.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,457\u001b[0m (13.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,265</span> (12.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,265\u001b[0m (12.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------Modelo-----------------------------------------------------\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(4,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "print(\"\\nâœ“ Modelo creado\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "generator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERADOR DE BATCHES ROBUSTO - SIN TIMEOUT\n",
      "================================================================================\n",
      "\n",
      "âœ“ Generador robusto configurado\n",
      "  Batch size: 4096\n",
      "  Batches/Ã©poca train: 400\n",
      "  Samples/Ã©poca: 1,638,400\n",
      "\n",
      "ğŸ’¡ Usa toLocalIterator() - Sin timeout, 100% RDD\n"
     ]
    }
   ],
   "source": [
    "#----------------------Generador ROBUSTO (Sin Timeout)----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERADOR DE BATCHES ROBUSTO - SIN TIMEOUT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "class RobustRDDBatchGenerator:\n",
    "    \"\"\"\n",
    "    Generador que usa toLocalIterator() en lugar de collect().\n",
    "    \n",
    "    VENTAJAS:\n",
    "    - No hay timeout (itera sin collect masivo)\n",
    "    - MÃ¡s eficiente en memoria\n",
    "    - MÃ¡s robusto para datasets grandes\n",
    "    - Sigue siendo 100% RDD\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rdd, batch_size=4096, num_batches_per_epoch=None):\n",
    "        self.rdd = rdd\n",
    "        self.batch_size = batch_size\n",
    "        self.total_samples = rdd.count()\n",
    "        \n",
    "        if num_batches_per_epoch:\n",
    "            self.num_batches = num_batches_per_epoch\n",
    "        else:\n",
    "            self.num_batches = max(1, self.total_samples // batch_size)\n",
    "    \n",
    "    def generate_batches(self, seed=42):\n",
    "        \"\"\"\n",
    "        Genera batches usando toLocalIterator.\n",
    "        \n",
    "        toLocalIterator:\n",
    "        - Itera sobre RDD SIN collect masivo\n",
    "        - No causa timeout\n",
    "        - Procesa particiÃ³n por particiÃ³n\n",
    "        - 100% RDD distribuido\n",
    "        \"\"\"\n",
    "        # Sample del RDD\n",
    "        fraction = min(1.0, (self.batch_size * self.num_batches) / self.total_samples)\n",
    "        sampled_rdd = self.rdd.sample(False, fraction, seed=seed)\n",
    "        \n",
    "        # Usar toLocalIterator en lugar de collect\n",
    "        batch_data = []\n",
    "        batch_count = 0\n",
    "        \n",
    "        # Iterar sin collect masivo\n",
    "        for item in sampled_rdd.toLocalIterator():\n",
    "            batch_data.append(item)\n",
    "            \n",
    "            # Cuando el batch estÃ¡ lleno, yield\n",
    "            if len(batch_data) >= self.batch_size:\n",
    "                X_batch = np.array([x[0] for x in batch_data], dtype=np.float32)\n",
    "                y_batch = np.array([x[1] for x in batch_data], dtype=np.float32)\n",
    "                \n",
    "                yield X_batch, y_batch\n",
    "                \n",
    "                batch_data = []\n",
    "                batch_count += 1\n",
    "                \n",
    "                # Limitar nÃºmero de batches\n",
    "                if batch_count >= self.num_batches:\n",
    "                    break\n",
    "        \n",
    "        # Ãšltimo batch parcial\n",
    "        if batch_data and batch_count < self.num_batches:\n",
    "            X_batch = np.array([x[0] for x in batch_data], dtype=np.float32)\n",
    "            y_batch = np.array([x[1] for x in batch_data], dtype=np.float32)\n",
    "            yield X_batch, y_batch\n",
    "\n",
    "# ConfiguraciÃ³n\n",
    "BATCH_SIZE = 4096  # Un poco mÃ¡s pequeÃ±o para ser mÃ¡s robusto\n",
    "BATCHES_PER_EPOCH_TRAIN = 400\n",
    "BATCHES_PER_EPOCH_VAL = 20\n",
    "\n",
    "train_generator = RobustRDDBatchGenerator(\n",
    "    train_rdd, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_batches_per_epoch=BATCHES_PER_EPOCH_TRAIN\n",
    ")\n",
    "\n",
    "test_generator = RobustRDDBatchGenerator(\n",
    "    test_rdd,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_batches_per_epoch=BATCHES_PER_EPOCH_VAL\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Generador robusto configurado\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Batches/Ã©poca train: {BATCHES_PER_EPOCH_TRAIN}\")\n",
    "print(f\"  Samples/Ã©poca: {BATCH_SIZE * BATCHES_PER_EPOCH_TRAIN:,}\")\n",
    "print(f\"\\nğŸ’¡ Usa toLocalIterator() - Sin timeout, 100% RDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENTRENAMIENTO 100% RDD - ROBUSTO\n",
      "================================================================================\n",
      "\n",
      "âš™ï¸  ConfiguraciÃ³n:\n",
      "   Ã‰pocas: 15\n",
      "   Batches/Ã©poca: 400\n",
      "   Batch size: 4096\n",
      "\n",
      "ğŸ¯ Iniciando...\n",
      "\n",
      "\n",
      "Ã‰poca 1/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 469.1248\n",
      "  Batch 200/400 - loss: 264.1448\n",
      "  Batch 300/400 - loss: 186.9661\n",
      "  Batch 400/400 - loss: 148.8105\n",
      "\n",
      "  ğŸ“Š Ã‰poca 1:\n",
      "     loss: 315.1734 - mae: 11.3691\n",
      "     val_loss: 143.1372 - val_mae: 6.7481\n",
      "     Tiempo: 62.1s\n",
      "\n",
      "Ã‰poca 2/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 122.0138\n",
      "  Batch 200/400 - loss: 107.8552\n",
      "  Batch 300/400 - loss: 97.4814\n",
      "  Batch 400/400 - loss: 89.6862\n",
      "\n",
      "  ğŸ“Š Ã‰poca 2:\n",
      "     loss: 109.2100 - mae: 5.6545\n",
      "     val_loss: 88.2205 - val_mae: 4.9640\n",
      "     Tiempo: 57.4s\n",
      "\n",
      "Ã‰poca 3/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 82.2312\n",
      "  Batch 200/400 - loss: 77.4876\n",
      "  Batch 300/400 - loss: 73.4865\n",
      "  Batch 400/400 - loss: 70.1736\n",
      "\n",
      "  ğŸ“Š Ã‰poca 3:\n",
      "     loss: 77.5771 - mae: 4.6030\n",
      "     val_loss: 69.4783 - val_mae: 4.3261\n",
      "     Tiempo: 55.8s\n",
      "\n",
      "Ã‰poca 4/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 66.6665\n",
      "  Batch 200/400 - loss: 64.2833\n",
      "  Batch 300/400 - loss: 62.1378\n",
      "  Batch 400/400 - loss: 60.2773\n",
      "\n",
      "  ğŸ“Š Ã‰poca 4:\n",
      "     loss: 64.2333 - mae: 4.1420\n",
      "     val_loss: 59.8862 - val_mae: 3.9878\n",
      "     Tiempo: 56.4s\n",
      "\n",
      "Ã‰poca 5/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 58.2060\n",
      "  Batch 200/400 - loss: 56.7438\n",
      "  Batch 300/400 - loss: 55.3634\n",
      "  Batch 400/400 - loss: 54.1178\n",
      "\n",
      "  ğŸ“Š Ã‰poca 5:\n",
      "     loss: 56.6721 - mae: 3.8698\n",
      "     val_loss: 53.8540 - val_mae: 3.7650\n",
      "     Tiempo: 68.6s\n",
      "\n",
      "Ã‰poca 6/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 52.7103\n",
      "  Batch 200/400 - loss: 51.6665\n",
      "  Batch 300/400 - loss: 50.6880\n",
      "  Batch 400/400 - loss: 49.7977\n",
      "\n",
      "  ğŸ“Š Ã‰poca 6:\n",
      "     loss: 51.6123 - mae: 3.6776\n",
      "     val_loss: 49.6094 - val_mae: 3.5975\n",
      "     Tiempo: 55.7s\n",
      "\n",
      "Ã‰poca 7/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 48.7850\n",
      "  Batch 200/400 - loss: 48.0108\n",
      "  Batch 300/400 - loss: 47.2708\n",
      "  Batch 400/400 - loss: 46.5751\n",
      "\n",
      "  ğŸ“Š Ã‰poca 7:\n",
      "     loss: 47.9595 - mae: 3.5287\n",
      "     val_loss: 46.4322 - val_mae: 3.4641\n",
      "     Tiempo: 56.3s\n",
      "\n",
      "Ã‰poca 8/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 45.8042\n",
      "  Batch 200/400 - loss: 45.1991\n",
      "  Batch 300/400 - loss: 44.6152\n",
      "  Batch 400/400 - loss: 44.0722\n",
      "\n",
      "  ğŸ“Š Ã‰poca 8:\n",
      "     loss: 45.1563 - mae: 3.4079\n",
      "     val_loss: 43.9679 - val_mae: 3.3554\n",
      "     Tiempo: 58.3s\n",
      "\n",
      "Ã‰poca 9/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 43.4615\n",
      "  Batch 200/400 - loss: 42.9704\n",
      "  Batch 300/400 - loss: 42.5004\n",
      "  Batch 400/400 - loss: 42.0586\n",
      "\n",
      "  ğŸ“Š Ã‰poca 9:\n",
      "     loss: 42.9378 - mae: 3.3089\n",
      "     val_loss: 41.9755 - val_mae: 3.2650\n",
      "     Tiempo: 63.4s\n",
      "\n",
      "Ã‰poca 10/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 41.5697\n",
      "  Batch 200/400 - loss: 41.1776\n",
      "  Batch 300/400 - loss: 40.7904\n",
      "  Batch 400/400 - loss: 40.4306\n",
      "\n",
      "  ğŸ“Š Ã‰poca 10:\n",
      "     loss: 41.1448 - mae: 3.2261\n",
      "     val_loss: 40.3650 - val_mae: 3.1896\n",
      "     Tiempo: 56.3s\n",
      "\n",
      "Ã‰poca 11/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 40.0321\n",
      "  Batch 200/400 - loss: 39.7003\n",
      "  Batch 300/400 - loss: 39.3729\n",
      "  Batch 400/400 - loss: 39.0760\n",
      "\n",
      "  ğŸ“Š Ã‰poca 11:\n",
      "     loss: 39.6742 - mae: 3.1569\n",
      "     val_loss: 39.0236 - val_mae: 3.1261\n",
      "     Tiempo: 55.9s\n",
      "\n",
      "Ã‰poca 12/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 38.7467\n",
      "  Batch 200/400 - loss: 38.4755\n",
      "  Batch 300/400 - loss: 38.2050\n",
      "  Batch 400/400 - loss: 37.9519\n",
      "\n",
      "  ğŸ“Š Ã‰poca 12:\n",
      "     loss: 38.4527 - mae: 3.0987\n",
      "     val_loss: 37.9093 - val_mae: 3.0726\n",
      "     Tiempo: 69.3s\n",
      "\n",
      "Ã‰poca 13/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 37.6671\n",
      "  Batch 200/400 - loss: 37.4387\n",
      "  Batch 300/400 - loss: 37.2073\n",
      "  Batch 400/400 - loss: 36.9864\n",
      "\n",
      "  ğŸ“Š Ã‰poca 13:\n",
      "     loss: 37.4171 - mae: 3.0489\n",
      "     val_loss: 36.9502 - val_mae: 3.0263\n",
      "     Tiempo: 55.0s\n",
      "\n",
      "Ã‰poca 14/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 36.7471\n",
      "  Batch 200/400 - loss: 36.5499\n",
      "  Batch 300/400 - loss: 36.3470\n",
      "  Batch 400/400 - loss: 36.1546\n",
      "\n",
      "  ğŸ“Š Ã‰poca 14:\n",
      "     loss: 36.5296 - mae: 3.0057\n",
      "     val_loss: 36.1306 - val_mae: 2.9862\n",
      "     Tiempo: 68.4s\n",
      "\n",
      "Ã‰poca 15/15\n",
      "------------------------------------------------------------\n",
      "  Batch 100/400 - loss: 35.9573\n",
      "  Batch 200/400 - loss: 35.7757\n",
      "  Batch 300/400 - loss: 35.5952\n",
      "  Batch 400/400 - loss: 35.4224\n",
      "\n",
      "  ğŸ“Š Ã‰poca 15:\n",
      "     loss: 35.7593 - mae: 2.9681\n",
      "     val_loss: 35.4005 - val_mae: 2.9506\n",
      "     Tiempo: 63.7s\n",
      "\n",
      "================================================================================\n",
      "âœ“ ENTRENAMIENTO COMPLETADO\n",
      "================================================================================\n",
      "  Tiempo: 15.04 minutos\n",
      "  Ã‰pocas: 15\n",
      "  Mejor val_loss: 35.4005\n"
     ]
    }
   ],
   "source": [
    "#----------------------Entrenamiento----------------------------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENTRENAMIENTO 100% RDD - ROBUSTO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "EPOCHS = 15\n",
    "\n",
    "print(f\"\\nâš™ï¸  ConfiguraciÃ³n:\")\n",
    "print(f\"   Ã‰pocas: {EPOCHS}\")\n",
    "print(f\"   Batches/Ã©poca: {BATCHES_PER_EPOCH_TRAIN}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "history = {'loss': [], 'mae': [], 'val_loss': [], 'val_mae': []}\n",
    "\n",
    "print(\"\\nğŸ¯ Iniciando...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"\\nÃ‰poca {epoch+1}/{EPOCHS}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_maes = []\n",
    "    \n",
    "    # Entrenar\n",
    "    batch_count = 0\n",
    "    try:\n",
    "        for X_batch, y_batch in train_generator.generate_batches(seed=epoch):\n",
    "            metrics = model.train_on_batch(X_batch, y_batch, return_dict=True)\n",
    "            epoch_losses.append(metrics['loss'])\n",
    "            epoch_maes.append(metrics['mae'])\n",
    "            batch_count += 1\n",
    "            \n",
    "            if batch_count % 100 == 0:\n",
    "                print(f\"  Batch {batch_count}/{BATCHES_PER_EPOCH_TRAIN} - \"\n",
    "                      f\"loss: {np.mean(epoch_losses[-20:]):.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error en batch {batch_count}: {e}\")\n",
    "        print(f\"  Continuando con siguiente Ã©poca...\")\n",
    "        continue\n",
    "    \n",
    "    if not epoch_losses:\n",
    "        print(\"  No se completaron batches, saltando Ã©poca\")\n",
    "        continue\n",
    "    \n",
    "    train_loss = np.mean(epoch_losses)\n",
    "    train_mae = np.mean(epoch_maes)\n",
    "    \n",
    "    # ValidaciÃ³n\n",
    "    val_losses = []\n",
    "    val_maes = []\n",
    "    for X_val, y_val in test_generator.generate_batches(seed=epoch):\n",
    "        val_metrics = model.test_on_batch(X_val, y_val, return_dict=True)\n",
    "        val_losses.append(val_metrics['loss'])\n",
    "        val_maes.append(val_metrics['mae'])\n",
    "    \n",
    "    val_loss = np.mean(val_losses) if val_losses else train_loss\n",
    "    val_mae = np.mean(val_maes) if val_maes else train_mae\n",
    "    \n",
    "    history['loss'].append(train_loss)\n",
    "    history['mae'].append(train_mae)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_mae'].append(val_mae)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f\"\\n  ğŸ“Š Ã‰poca {epoch+1}:\")\n",
    "    print(f\"     loss: {train_loss:.4f} - mae: {train_mae:.4f}\")\n",
    "    print(f\"     val_loss: {val_loss:.4f} - val_mae: {val_mae:.4f}\")\n",
    "    print(f\"     Tiempo: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epoch > 3 and val_loss > history['val_loss'][-2]:\n",
    "        patience = getattr(model, 'patience', 0) + 1\n",
    "        model.patience = patience\n",
    "        if patience >= 3:\n",
    "            print(f\"\\nâš ï¸  Early stopping\")\n",
    "            break\n",
    "    else:\n",
    "        model.patience = 0\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ“ ENTRENAMIENTO COMPLETADO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  Tiempo: {training_time/60:.2f} minutos\")\n",
    "print(f\"  Ã‰pocas: {len(history['loss'])}\")\n",
    "print(f\"  Mejor val_loss: {min(history['val_loss']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "evaluate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluando modelo...\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS\n",
      "================================================================================\n",
      "\n",
      "  RÂ²:   0.8876 (88.8%)\n",
      "  RMSE: $5.5770\n",
      "  MAE:  $2.6594\n",
      "  MAPE: 20.59%\n",
      "\n",
      "  Evaluado en 409,208 predicciones\n"
     ]
    }
   ],
   "source": [
    "#----------------------EvaluaciÃ³n-------------------------------------------------\n",
    "print(\"\\nEvaluando modelo...\")\n",
    "\n",
    "eval_generator = RobustRDDBatchGenerator(\n",
    "    test_rdd,\n",
    "    batch_size=4096,\n",
    "    num_batches_per_epoch=100\n",
    ")\n",
    "\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "\n",
    "for X_test, y_test_batch in eval_generator.generate_batches(seed=99):\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    all_predictions.extend(y_pred.flatten().tolist())\n",
    "    all_actuals.extend(y_test_batch.tolist())\n",
    "\n",
    "y_test_eval = np.array(all_actuals)\n",
    "y_pred_eval = np.array(all_predictions)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test_eval, y_pred_eval)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_eval, y_pred_eval)\n",
    "r2 = r2_score(y_test_eval, y_pred_eval)\n",
    "mape = np.mean(np.abs((y_test_eval - y_pred_eval) / y_test_eval)) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTADOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n  RÂ²:   {r2:.4f} ({r2*100:.1f}%)\")\n",
    "print(f\"  RMSE: ${rmse:.4f}\")\n",
    "print(f\"  MAE:  ${mae:.4f}\")\n",
    "print(f\"  MAPE: {mape:.2f}%\")\n",
    "print(f\"\\n  Evaluado en {len(y_test_eval):,} predicciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------Guardar----------------------------------------------------\n",
    "#os.makedirs(\"modelos\", exist_ok=True)\n",
    "#model_path = f\"modelos/taxi_100RDD_ROBUSTO_{datetime.now().strftime('%Y%m%d_%H%M%S')}.h5\"\n",
    "#model.save(model_path)\n",
    "#print(f\"\\nâœ“ Modelo guardado: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
